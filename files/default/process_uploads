#!/usr/bin/env ruby

# Generated by Chef for <%= node['fqdn'] %>
# Local modifications will be overwritten.

gem 'aws-sdk', '~> 1.0'
require 'aws-sdk'
require 'find'
require 'shellwords'
require 'fileutils'
require 'net/http'
require 'net/http/post/multipart'
require 'uri'
require 'json'
require 'zlib'
require 'zip'
require 'date'
require 'yaml'

def conf
  @conf ||= YAML.load_file('/opt/evertrue/config.yml')
end

def auth_oid_query_string(oid)
  @auth_oid_query_string ||= "?oid=#{oid}&auth=#{conf[:upload_auth_token]}&auth_provider=evertrueapptoken&app_key=#{conf[:upload_app_key]}"
end

def auth_query_string
  @auth_query_string ||= "?auth=#{conf[:upload_auth_token]}&auth_provider=evertrueapptoken&app_key=#{conf[:upload_app_key]}"
end

def get_from_api(uri)
  uri = URI.parse(URI.encode(uri))

  http = Net::HTTP.new(uri.host, uri.port)
  http.use_ssl = true

  req = Net::HTTP::Get.new(uri.request_uri)
  response = http.request(req)
  fail "API error, Response: #{response.code}, body: #{response.body}" unless response.code.to_i == 200

  JSON.parse(response.body)
end

def post_to_api(uri, data, options = {})
  uri = URI.parse(URI.encode(uri))
  http = Net::HTTP.new(uri.host, uri.port)
  http.use_ssl = true

  req = (if options[:method] == 'put'
           Net::HTTP::Put.new(uri.request_uri)
         else
           Net::HTTP::Post.new(uri.request_uri)
         end)

  unless data.empty?
    req['Content-Type'] = 'application/json'
    req.body = data.to_json
  end

  response = http.request(req)
  fail "Error posting to API, data: #{data.inspect}. Response: " \
       "#{response.code}, body: #{response.body}" unless response.code.to_i == 200

  JSON.parse(response.body)
end

def get_dna(org_slug, key)
  get_from_api(conf[:api_url] + "/1.0/#{org_slug}/dna/#{key}")['response']['data']
rescue Exception => e
  puts "Error sending org_slug: #{org_slug}"
  puts e.message
  puts e.backtrace
end

def send_to_s3(org_slug, path)
  s3 = AWS::S3.new(
    access_key_id: conf[:aws_access_key_id],
    secret_access_key: conf[:aws_secret_access_key]
  )
  bucket = s3.buckets['onboarding.evertrue.com']
  now = DateTime.now.strftime('%Q')
  s3_filename = "#{now}-#{File.basename(path)}"
  bucket.objects["#{org_slug}/data/#{s3_filename}"].write(Pathname.new(path))
  s3_filename
end

def get_oid(org_slug)
  get_from_api(conf[:api_url] + "/auth/organizations/slug/#{org_slug}" + auth_query_string)['id']
rescue Exception => e
  puts "Error sending org_slug: #{org_slug}"
  puts e.message
  puts e.backtrace
end

def get_header_change_status_from_importer(oid, s3_filename, compression, gift_import)
  data = { 's3_filename' => s3_filename, 'notify' => 1, 'compression' => compression }
  data['type'] = 'TRANSACTIONAL_CSV' if gift_import

  post_to_api(conf[:api_url] + '/importer/v1/jobs/mapping_check' + auth_oid_query_string(oid), data)['mapping_exists']
rescue Exception => e
  puts "Error sending oid: #{oid}, s3_filename: #{s3_filename}"
  puts e.message
  puts e.backtrace
end

def post_to_new_importer(oid, s3_filename, compression, full_import, gift_import)
  data = { 's3_filename' => s3_filename, 'notify' => 1, 'compression' => compression }

  if gift_import
    data['type'] = 'TRANSACTIONAL_CSV'
  else
    data['prune'] = full_import
  end

  post_to_api(conf[:api_url] + '/importer/v1/jobs' + auth_oid_query_string(oid), data)['id']
rescue Exception => e
  puts "Error sending oid: #{oid}, s3_filename: #{s3_filename}"
  puts e.message
  puts e.backtrace
end

def queue_to_new_importer(oid, job_id)
  post_to_api(conf[:api_url] + "/importer/v1/jobs/queue/#{job_id}" + auth_oid_query_string(oid), {})
rescue Exception => e
  puts "Error queueing oid: #{oid}, job_id: #{job_id}"
  puts e.message
  puts e.backtrace
end

def compress_if_not_already(path, compression)
  return path if compression != 'NONE'

  Zlib::GzipWriter.open("#{path}.gz", Zlib::BEST_COMPRESSION) do |gz|
    gz.mtime = File.mtime(path)
    gz.orig_name = File.basename(path)
    File.open(path) do |f|
      IO.copy_stream(f, gz)
    end
  end

  FileUtils.rm(path)
  "#{path}.gz"
end

def process(org_slug, path, compression)
  return unless `lsof #{Shellwords.shellescape path}`.empty?
  uploaded = false

  full_import = !(File.basename(path) =~ /\.full\./i).nil?
  gift_import = !(File.basename(path) =~ /\.gifts\./i).nil?

  oid = get_oid(org_slug)
  s3_filename = send_to_s3(org_slug, path)

  mappingExists = get_header_change_status_from_importer(oid, s3_filename, compression, gift_import)
  job_id = post_to_new_importer(oid, s3_filename, compression, full_import, gift_import)

  if mappingExists
    auto_ingest_dna_value = get_dna(org_slug, 'ET.Importer.IngestionMode')
    auto_ingest = auto_ingest_dna_value.nil? || auto_ingest_dna_value != 'AutoIngest'

    if auto_ingest
      puts "skipped auto-ingestion for #{org_slug}"
    else
      queue_to_new_importer(oid, job_id)

      puts "sent file #{path} for processing"
      uploaded = true
    end
  else
    data = { 'value' => 'NotifyOnly' }
    post_to_api(conf[:api_url] + '/dna/setting_values/ET.Importer.IngestionMode' + auth_oid_query_string(oid), data, method: 'put')

    puts "Error processing #{path} for #{org_slug}: CSV headers not recognized"
  end

  compressed_path = compress_if_not_already(path, compression)

  FileUtils.chmod(0700, compressed_path)
  FileUtils.chown('root', 'root', compressed_path)
  FileUtils.mv(compressed_path, conf[:archive_dir])

  uploaded
end

def main
  processed_users = conf[:unames].each_with_object([]) do |uname, processed_usernames|
    next if uname == 'trial0928'
    org_slug = /(.*?)\d+$/.match(uname)[1]

    begin
      Find.find("#{conf[:upload_dir]}/#{uname}/uploads") do |path|
        begin
          compression_type = (
            case path
            when /.*\.csv$/i
              'NONE'
            when /.*\.gz$/i
              'GZIP'
            when /.*\.zip$/i
              'ZIP'
            else
              next
            end
          )

          uploaded = process(org_slug, path, compression_type)
          processed_usernames << uname if uploaded
        rescue => e
          puts "Error processing path #{path}: #{e}"
          puts e.backtrace
        end
      end
    rescue => e
      puts "Error processing org #{org_slug}: #{e}"
      puts e.backtrace
    end
  end

  puts "Uploaded data from: #{processed_users.join(', ')}" unless processed_users.empty?
end

main
